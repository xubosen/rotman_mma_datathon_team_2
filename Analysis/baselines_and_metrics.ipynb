{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Rotman Data Science Competition\n",
    "## Section 2.1: Baselines & Evaluation Metrics\n",
    "Some part of this code may be slow, but everything should run in less than 5 minutes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_competition_data() -> pd.DataFrame:\n",
    "    \"\"\" Load the data for the competition \"\"\"\n",
    "\n",
    "    # Path where you saved your data\n",
    "    DATA_PATH = \"data/mma_mart.csv\" # <- change this to your data path\n",
    "    data = pd.read_csv(DATA_PATH)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   order_id  product_id                                   product_name  \\\n0         1       49302                               Bulgarian Yogurt   \n1         1       11109  Organic 4% Milk Fat Whole Milk Cottage Cheese   \n2         1       10246                          Organic Celery Hearts   \n3         1       49683                                 Cucumber Kirby   \n4         1       43633           Lightly Smoked Sardines in Olive Oil   \n\n   aisle_id                 aisle  department_id    department  \n0       120                yogurt             16    dairy eggs  \n1       108  other creams cheeses             16    dairy eggs  \n2        83      fresh vegetables              4       produce  \n3        83      fresh vegetables              4       produce  \n4        95   canned meat seafood             15  canned goods  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>product_id</th>\n      <th>product_name</th>\n      <th>aisle_id</th>\n      <th>aisle</th>\n      <th>department_id</th>\n      <th>department</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>49302</td>\n      <td>Bulgarian Yogurt</td>\n      <td>120</td>\n      <td>yogurt</td>\n      <td>16</td>\n      <td>dairy eggs</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11109</td>\n      <td>Organic 4% Milk Fat Whole Milk Cottage Cheese</td>\n      <td>108</td>\n      <td>other creams cheeses</td>\n      <td>16</td>\n      <td>dairy eggs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>10246</td>\n      <td>Organic Celery Hearts</td>\n      <td>83</td>\n      <td>fresh vegetables</td>\n      <td>4</td>\n      <td>produce</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>49683</td>\n      <td>Cucumber Kirby</td>\n      <td>83</td>\n      <td>fresh vegetables</td>\n      <td>4</td>\n      <td>produce</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>43633</td>\n      <td>Lightly Smoked Sardines in Olive Oil</td>\n      <td>95</td>\n      <td>canned meat seafood</td>\n      <td>15</td>\n      <td>canned goods</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mma_data = load_competition_data()\n",
    "mma_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 0.1 Split Data into Train and Test Sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "TRAIN_TEST_SEED = 42 # Specify random state 42 for reproducibility.\n",
    "TEST_SIZE = 0.2 # Use 20% of the data for testing.\n",
    "mma_orders = mma_data[\"order_id\"].unique() # Get all unique order ids\n",
    "\n",
    "# Split the orders into train and test sets\n",
    "train_orders, test_orders = train_test_split(mma_orders, test_size=TEST_SIZE, random_state=TRAIN_TEST_SEED)\n",
    "\n",
    "# Retrieve all the purchases in the train and test order sets\n",
    "mma_train = mma_data[mma_data[\"order_id\"].isin(train_orders)]\n",
    "mma_test = mma_data[mma_data[\"order_id\"].isin(test_orders)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Evaluation Metrics\n",
    "### a) The number of orders that utilize the in-aisle items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def metric_a(test_data: pd.DataFrame, insta_aisle: list) -> float:\n",
    "    \"\"\" Return the number of orders that utilize the in-aisle items as a percentage of the total number of orders in the test_data dataset.\n",
    "\n",
    "    Precondition:\n",
    "    len(insta_aisle) == 1000\n",
    "    len(test_data) > 0\n",
    "    \"\"\"\n",
    "    # Count the orders that utilize in-aisle items\n",
    "    ## Filter the data to only include orders that purchased at least one item in the aisle\n",
    "    purchases_in_aisle = test_data[test_data[\"product_id\"].isin(insta_aisle)]\n",
    "\n",
    "    ## Count the number of orders that include at least one item in the aisle\n",
    "    orders_in_aisle = purchases_in_aisle[\"order_id\"].nunique()\n",
    "\n",
    "    ## Count the total number of orders in the test data\n",
    "    total_orders = test_data[\"order_id\"].nunique()\n",
    "\n",
    "    # Return the percentage of orders that utilize in-aisle items\n",
    "    result = (orders_in_aisle / total_orders) * 100\n",
    "\n",
    "\n",
    "    # Check for errors for debugging purposes\n",
    "    if total_orders <= 0:\n",
    "        raise ValueError(\"There must be at least one order in the test data\")\n",
    "\n",
    "    if len(insta_aisle) != 1000:\n",
    "        raise ValueError(\"insta_aisle must contain 1000 product ids\")\n",
    "\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (b) Average % of items in each order that utilize in-aisle items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def metric_b(test_data: pd.DataFrame, insta_aisle: list) -> float:\n",
    "    \"\"\" Calculate the percentage of items in each order that utilize in-aisle items and return the average of these percentages.\n",
    "\n",
    "    Precondition:\n",
    "    len(insta_aisle) == 1000\n",
    "    \"\"\"\n",
    "    # Check for errors for debugging purposes\n",
    "    if len(insta_aisle) != 1000:\n",
    "        raise ValueError(\"There should be 1000 items in the aisle\")\n",
    "\n",
    "\n",
    "    # Copy data to prevent altering test_data\n",
    "    test_data_copy = test_data.copy()\n",
    "\n",
    "    # Add column that is 1 if the product id is in insta_aisle and 0 if not\n",
    "    test_data_copy[\"is_utilized\"] = test_data_copy[\"product_id\"].isin(insta_aisle).astype(int)\n",
    "\n",
    "    # Sum the new column and divide by total number of items in order\n",
    "    ## Get a map mapping order_id to the number of items in the order that are utilized\n",
    "    order_to_ultilized_items = test_data_copy.groupby(\"order_id\")[\"is_utilized\"].sum()\n",
    "\n",
    "    ## Get a map mapping order_id to the total number of items in the order\n",
    "    order_to_total_items = test_data_copy.groupby(\"order_id\")[\"order_id\"].count()\n",
    "\n",
    "    ## Divide the two maps to get order to the percentage of items in the order that are utilized\n",
    "    order_to_precent_ultilization = order_to_ultilized_items/order_to_total_items\n",
    "\n",
    "\n",
    "    # Return average of percentage ultilization over all orders\n",
    "    return order_to_precent_ultilization.mean() * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (c) Average of Metric a and Metric b (Do not use on large datasets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def metric_average(test_data: pd.DataFrame, insta_aisle: list) -> float:\n",
    "    \"\"\" Return the average of metric a and metric b\n",
    "\n",
    "    Precondition:\n",
    "    len(insta_aisle) == 1000\n",
    "    \"\"\"\n",
    "    return (metric_a(test_data, insta_aisle) + metric_b(test_data, insta_aisle)) / 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (d) Average % of items in each order that utilize in-aisle items accounting for any identified substitutes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Baseline Approach\n",
    "Identify top 1000 items sold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def baseline(data: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    \"\"\" Return the top k items by sales\n",
    "\n",
    "    Precondition:\n",
    "    k is less than the number of items in the dataset\n",
    "    \"\"\"\n",
    "    # Count number of orders for each product\n",
    "    sales = pd.DataFrame(data.groupby(\"product_id\")[\"order_id\"].count())\n",
    "\n",
    "    # Rename column to sales and sort by sales\n",
    "    sales.rename(columns = {\"order_id\": \"sales\"}, inplace=True)\n",
    "    sales.sort_values(by=\"sales\", ascending=False, inplace=True)\n",
    "    sales.reset_index(inplace=True)\n",
    "\n",
    "    # Catch errors for debugging purposes\n",
    "    if k > sales.shape[0]:\n",
    "        raise ValueError(\"k must be less than the number of items in the dataset\")\n",
    "\n",
    "    # Return top k items by sales (i.e. top k items with most orders)\n",
    "    return sales.iloc[:k]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate the baseline approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   product_id  sales\n0       24852  11623\n1       13176   9335\n2       21137   6466\n3       21903   5947\n4       47209   5081",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24852</td>\n      <td>11623</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13176</td>\n      <td>9335</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21137</td>\n      <td>6466</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21903</td>\n      <td>5947</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47209</td>\n      <td>5081</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 1000 items by sales\n",
    "baseline_pred = baseline(mma_train, 1000)\n",
    "baseline_pred.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric a: 92.42091276128176, Metric b: 53.77052784045304, Avg Score: 73.0957203008674\n"
     ]
    }
   ],
   "source": [
    "# Convert baseline_pred to a list\n",
    "baseline_insta_aisle = baseline_pred[\"product_id\"].tolist()\n",
    "\n",
    "# Check that there are 1000 items in the aisle\n",
    "if len(baseline_insta_aisle) != 1000:\n",
    "    raise ValueError(\"There should be 1000 items in the aisle\")\n",
    "\n",
    "# Run metrics on the baseline aisle\n",
    "met_a_base = metric_a(mma_test, baseline_insta_aisle)\n",
    "met_b_base = metric_b(mma_test, baseline_insta_aisle)\n",
    "print(f\"Metric a: {met_a_base}, Metric b: {met_b_base}, Avg Score: {(met_a_base + met_b_base) / 2}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Optimizing Metric a\n",
    "Create algorithm that optimizes over the test set to serve as a theoretical maximum of how well our approaches can do. (I personally call them psychic algorithms because you would have to have superpowers and apply them over the test set, while in real life the test set exists only in the future)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def max_metric_a_aisle(data: pd.DataFrame) -> list:\n",
    "    \"\"\" Return the aisle that maximizes metric a over the data. Do this by first getting the item with most sales, then getting the item with most sales in orders that do not contain the first item, and so on. For why this produces max list, see proof writeup.\n",
    "    \"\"\"\n",
    "    return _max_metric_a_recur_helper(data, [])\n",
    "\n",
    "def _max_metric_a_recur_helper(data: pd.DataFrame, aisle: list) -> list:\n",
    "    \"\"\" Return the aisle that maximizes metric a over the data. Do this by first getting the item with most sales, then getting the item with most sales in orders that do not contain the first item, and so on.\n",
    "\n",
    "    Precondition:\n",
    "    - data must be a subset of the test data\n",
    "    - aisle must be a subset of the top 1000 items by sales\n",
    "    \"\"\"\n",
    "    # Base case\n",
    "    if len(aisle) == 1000:\n",
    "        return aisle\n",
    "\n",
    "    else:\n",
    "        # Get the top item by sales in data\n",
    "        top_item = get_top_product(data)\n",
    "\n",
    "        # Add top item to aisle\n",
    "        aisle.append(top_item)\n",
    "\n",
    "        # Filter data to only include orders that do not contain the top item\n",
    "        top_item_orders = data[data[\"product_id\"] == top_item]\n",
    "        data_excluding_top_item = data[~data[\"order_id\"].isin(top_item_orders[\"order_id\"])]\n",
    "\n",
    "        # Recursively call helper function\n",
    "        return _max_metric_a_recur_helper(data_excluding_top_item, aisle)\n",
    "\n",
    "def get_top_product(data: pd.DataFrame) -> list:\n",
    "    \"\"\" Return the top item by sales in data. \"\"\"\n",
    "    # Count number of orders for each product\n",
    "    sales = pd.DataFrame(data.groupby(\"product_id\")[\"order_id\"].count())\n",
    "\n",
    "    # Rename column to sales\n",
    "    sales.rename(columns = {\"order_id\": \"sales\"}, inplace=True)\n",
    "\n",
    "    # Get top item by sales\n",
    "    sales.reset_index(inplace=True) # Reset index so we don't get multiple items if there is a tie\n",
    "    top_item =  sales.loc[sales[\"sales\"].idxmax()][\"product_id\"]\n",
    "\n",
    "    return top_item"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Metric a: 96.78029335105023\n",
      "CPU times: user 3.42 s, sys: 476 ms, total: 3.9 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Max Metric a for the test set\n",
    "met_a_top_1000 = max_metric_a_aisle(mma_test)\n",
    "print(f\"Max Metric a: {metric_a(mma_test, met_a_top_1000)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Optimizing Metric b\n",
    "### a) Add more columns to the data\n",
    "Optimizing metric b is more complicated. We will start by adding an \"order size\" column to the data.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.8 ms, sys: 28.9 ms, total: 92.7 ms\n",
      "Wall time: 90.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "order_id_to_order_size = mma_data.groupby(\"order_id\")[\"order_id\"].count()\n",
    "mma_data_aug = mma_data.copy()\n",
    "mma_data_aug[\"order_size\"] = mma_data_aug[\"order_id\"].map(order_id_to_order_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculate the proportion of each product in its current order and add it as a column to the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# This is just 1 / the order size\n",
    "mma_data_aug.loc[:, \"portion_of_order\"] = 1/mma_data_aug[\"order_size\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get the same train test split from mma_data_aug"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Get the same train test split from mma_data_aug\n",
    "mma_train_aug = mma_data_aug[mma_data_aug[\"order_id\"].isin(train_orders)]\n",
    "mma_test_aug = mma_data_aug[mma_data_aug[\"order_id\"].isin(test_orders)]\n",
    "\n",
    "# Check that mma_data_aug is the same as mma_data\n",
    "data_is_same = mma_data_aug.loc[:, \"order_id\" : \"department\"].equals(mma_data)\n",
    "train_is_same = mma_train_aug.loc[:, \"order_id\" : \"department\"].equals(mma_train)\n",
    "test_is_same = mma_test_aug.loc[:, \"order_id\" : \"department\"].equals(mma_test)\n",
    "\n",
    "# Check that all of these are the same as their non-augmented counterparts if we remove the augmented column\n",
    "if not (data_is_same and train_is_same and test_is_same):\n",
    "    raise ValueError(\"the new train test split is not the same as the old ones\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c) Demonstrate an alternative way of calculating metric b that would allow us to optimize over it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### First way of calculating metric b (the one from Case pdf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def metric_b_method_1(data, aisle) -> float:\n",
    "    \"\"\" Calculate metric b over data with aisle using the 1st process clearly represented in the mathematical proof\n",
    "\n",
    "    Warning:\n",
    "    This is really slow, but it imitates the math closely. This should only be used for demonstration purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    A = aisle\n",
    "    B = data.set_index(\"order_id\")\n",
    "    B_size = data[\"order_id\"].nunique()\n",
    "\n",
    "    met_b = 0\n",
    "    for k in data[\"order_id\"].unique():\n",
    "        b_k = B.loc[k]\n",
    "\n",
    "        # Handle special case where there is only one item in the order and pandas freaks out\n",
    "        if isinstance(b_k[\"product_id\"], np.int64): # If this is true, then there is only one item in the order\n",
    "            if b_k[\"product_id\"] in A:\n",
    "                met_b += 1.0\n",
    "            else:\n",
    "                met_b += 0.0 # This is not necessary, but done for clarity\n",
    "\n",
    "        # Handle all the other cases\n",
    "        else:\n",
    "            b_k_intersect_A = b_k[b_k[\"product_id\"].isin(A)]\n",
    "            b_k_intersect_A_size = b_k_intersect_A.shape[0]\n",
    "            b_k_size = b_k.shape[0]\n",
    "\n",
    "            met_b += b_k_intersect_A_size / b_k_size\n",
    "\n",
    "    return (met_b / B_size) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Second way of calculating metric b (the one from my mathematical proof)\n",
    "The alternate way is written in more detail in the proof write up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def metric_b_impact_score(data_aug, product_id) -> float:\n",
    "    \"\"\" Return the metric b impact score for a single product id given data_aug. \"\"\"\n",
    "    return data_aug[data_aug[\"product_id\"] == product_id][\"portion_of_order\"].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def metric_b_method_2(data_aug, aisle) -> float:\n",
    "    \"\"\" Calculate metric b over data with aisle using the second process clearly represented in the mathematical proof\n",
    "\n",
    "    Warning:\n",
    "    This is also kinda slow, but is done intentionally to show that it reproduces the math\n",
    "\n",
    "    Precondition:\n",
    "    - data_aug must have the column \"portion_of_order\"\n",
    "    \"\"\"\n",
    "    A = aisle\n",
    "    B = data_aug\n",
    "    B_size = data_aug[\"order_id\"].nunique()\n",
    "\n",
    "    met_b = 0\n",
    "    for p in A:\n",
    "        met_b += metric_b_impact_score(B, p)\n",
    "\n",
    "    return (met_b / B_size) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Show that the alternate ways of calculating metric b are equivalent via code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.770527840453155\n",
      "CPU times: user 9.62 s, sys: 35.9 ms, total: 9.66 s\n",
      "Wall time: 9.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate metric b on the baseline isle with method 1\n",
    "met_b_method_1 = metric_b_method_1(mma_test_aug, baseline_insta_aisle)\n",
    "print(met_b_method_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.7705278404531\n",
      "CPU times: user 750 ms, sys: 25.9 ms, total: 776 ms\n",
      "Wall time: 775 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate metric b on the baseline isle with method 2\n",
    "met_b_method_2 = metric_b_method_2(mma_test_aug, baseline_insta_aisle)\n",
    "print(met_b_method_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the two methods are the same to the 10th decimal place. We don't check all decimal places because of floating point errors. In fact, 10 decimal places is probably overkill.\n",
    "round(met_b_method_1, 10) == round(met_b_method_2, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: 53.771, Method 2: 53.771, Metric b Function: 53.771\n"
     ]
    }
   ],
   "source": [
    "met_b = metric_b(mma_test_aug, baseline_insta_aisle)\n",
    "print(f\"Method 1: {round(met_b_method_1, 3)}, Method 2: {round(met_b_method_2, 3)}, Metric b Function: {round(met_b_base, 3)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create psychic algorithm for metric b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def max_metric_b_aisle(data_aug: pd.DataFrame) -> list:\n",
    "    \"\"\" Return the aisle that maximizes metric b over the data. This is run on the test set rather than the train set. data_aug must contain the column \"portion_of_order\"\"\"\n",
    "\n",
    "    data_aug_copy = data_aug.copy()\n",
    "    id_to_met_b_score = data_aug_copy.groupby(\"product_id\")[\"portion_of_order\"].sum()\n",
    "    data_aug_copy[\"met_b_score\"] = data_aug_copy[\"product_id\"].map(id_to_met_b_score)\n",
    "\n",
    "    # Get top 1000 metric b items\n",
    "    met_b_top_1000 = data_aug_copy.sort_values(by=\"met_b_score\", ascending=False)\n",
    "    met_b_top_1000.drop(columns=\"order_id\", inplace=True)\n",
    "    met_b_top_1000.drop_duplicates(subset=\"product_id\", inplace=True)\n",
    "    met_b_top_1000.reset_index(drop=True, inplace=True)\n",
    "    met_b_top_1000 = met_b_top_1000.iloc[:1000][\"product_id\"].tolist()\n",
    "\n",
    "    return met_b_top_1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Metric b: 55.050803135830165\n"
     ]
    }
   ],
   "source": [
    "met_b_top_1000 = max_metric_b_aisle(mma_test_aug)\n",
    "print(f\"Max Metric b: {metric_b(mma_test_aug, met_b_top_1000)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d) Checkpoint to save our improved dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70 ms, sys: 16.6 ms, total: 86.6 ms\n",
      "Wall time: 84.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "   order_id  product_id                                   product_name  \\\n0         1       49302                               Bulgarian Yogurt   \n1         1       11109  Organic 4% Milk Fat Whole Milk Cottage Cheese   \n2         1       10246                          Organic Celery Hearts   \n3         1       49683                                 Cucumber Kirby   \n4         1       43633           Lightly Smoked Sardines in Olive Oil   \n\n   aisle_id                 aisle  department_id    department  order_size  \\\n0       120                yogurt             16    dairy eggs           8   \n1       108  other creams cheeses             16    dairy eggs           8   \n2        83      fresh vegetables              4       produce           8   \n3        83      fresh vegetables              4       produce           8   \n4        95   canned meat seafood             15  canned goods           8   \n\n   portion_of_order  b_score (full dataset)  \n0             0.125                0.559483  \n1             0.125               13.620500  \n2             0.125               63.502058  \n3             0.125              255.053694  \n4             0.125                1.889912  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>product_id</th>\n      <th>product_name</th>\n      <th>aisle_id</th>\n      <th>aisle</th>\n      <th>department_id</th>\n      <th>department</th>\n      <th>order_size</th>\n      <th>portion_of_order</th>\n      <th>b_score (full dataset)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>49302</td>\n      <td>Bulgarian Yogurt</td>\n      <td>120</td>\n      <td>yogurt</td>\n      <td>16</td>\n      <td>dairy eggs</td>\n      <td>8</td>\n      <td>0.125</td>\n      <td>0.559483</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11109</td>\n      <td>Organic 4% Milk Fat Whole Milk Cottage Cheese</td>\n      <td>108</td>\n      <td>other creams cheeses</td>\n      <td>16</td>\n      <td>dairy eggs</td>\n      <td>8</td>\n      <td>0.125</td>\n      <td>13.620500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>10246</td>\n      <td>Organic Celery Hearts</td>\n      <td>83</td>\n      <td>fresh vegetables</td>\n      <td>4</td>\n      <td>produce</td>\n      <td>8</td>\n      <td>0.125</td>\n      <td>63.502058</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>49683</td>\n      <td>Cucumber Kirby</td>\n      <td>83</td>\n      <td>fresh vegetables</td>\n      <td>4</td>\n      <td>produce</td>\n      <td>8</td>\n      <td>0.125</td>\n      <td>255.053694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>43633</td>\n      <td>Lightly Smoked Sardines in Olive Oil</td>\n      <td>95</td>\n      <td>canned meat seafood</td>\n      <td>15</td>\n      <td>canned goods</td>\n      <td>8</td>\n      <td>0.125</td>\n      <td>1.889912</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Add a column to the data that is the metric b impact score for each product calculated over the full dataset\n",
    "id_to_met_b_score = mma_data_aug.groupby(\"product_id\")[\"portion_of_order\"].sum()\n",
    "id_to_met_b_score_dict = id_to_met_b_score.to_dict()\n",
    "\n",
    "mma_data_aug[\"b_score (full dataset)\"] = mma_data_aug[\"product_id\"].map(id_to_met_b_score)\n",
    "mma_data_aug.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "AUGMENTED_DATA_SAVE_PATH = \"./data/mma_mart_augmented.csv\" # <- change this to your augmented data path\n",
    "SAVE_MMA_DATA_AUG = True # <- change this to True if you want to save the augmented data\n",
    "LOAD_AUGMENTED_MMA_DATA = False # <- change this to True if you already saved the augmented data\n",
    "\n",
    "if SAVE_MMA_DATA_AUG:\n",
    "    # Save the augmented data so we don't have to do all of that again (could be slow on larger datasets)\n",
    "    mma_data_aug.to_csv(AUGMENTED_DATA_SAVE_PATH, index=False)\n",
    "    SAVE_MMA_DATA = False\n",
    "elif LOAD_AUGMENTED_MMA_DATA:\n",
    "    # Load the augmented data\n",
    "    mma_data_aug = pd.read_csv(AUGMENTED_DATA_SAVE_PATH)\n",
    "    LOAD_AUGMENTED_MMA_DATA = False\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
