{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Rotman Data Science Competition\n",
    "### A no-brainer implementation to use text-infilling to calculate similarity score between different substitute products\n",
    "## Imports\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "today_date = datetime.today()\n",
    "\n",
    "DATA_SAVE_PATH = \"./data/formated_data_for_seq2seq.csv\"\n",
    "CHECKPOINT_SAVE_PATH = f\"./substitute_classifier/T5/checkpoint_{today_date}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "### Turning our data into format for text-infilling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "REPROCESS_DATA = False\n",
    "if REPROCESS_DATA:\n",
    "    DATA_PATH = \"./data/mma_mart.csv\"\n",
    "    raw_data = pd.read_csv(DATA_PATH)\n",
    "    raw_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "if REPROCESS_DATA:\n",
    "    products = raw_data.loc[:, 'product_id' : 'product_name']\n",
    "    products.drop_duplicates(\"product_id\", inplace=True)\n",
    "    products.set_index(\"product_id\", inplace=True)\n",
    "    raw_data = raw_data.loc[:, 'order_id':'product_name']\n",
    "    raw_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if REPROCESS_DATA:\n",
    "    # Put orders into string format\n",
    "    FORMAT = \"On order {x} a customer bought {item 1, ... , item y}.\"\n",
    "\n",
    "    raw_data[\"str_p_id\"] = [f\"(id {str(i)})\" for i in raw_data[\"product_id\"]]\n",
    "    raw_data[\"target_text\"] = raw_data[\"product_name\"] + raw_data[\"str_p_id\"]\n",
    "    # raw_data.drop(columns=[\"product_id\", \"product_name\", \"str_p_id\"], inplace=True)\n",
    "    raw_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "if REPROCESS_DATA:\n",
    "    # Pick about 15% of the items to mask out\n",
    "    MASK_RATE = 0.15\n",
    "    RANDOM_SEED = 42\n",
    "    random_generator = np.random.default_rng(RANDOM_SEED)\n",
    "    mask_idx = random_generator.choice(raw_data.index, size= int(raw_data.shape[0] * MASK_RATE), replace=False, axis=0)\n",
    "    mask_idx[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "if REPROCESS_DATA:\n",
    "    raw_data_masked = raw_data.copy()\n",
    "    raw_data_masked.loc[mask_idx, \"target_text\"] = \"[MASK]\"\n",
    "    raw_data_masked.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "if REPROCESS_DATA:\n",
    "    formated_data = pd.DataFrame(columns=[\"source_text\", \"target_text\"], index=raw_data.order_id.unique())\n",
    "    formated_data.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "if REPROCESS_DATA:\n",
    "    FORMAT = \"On order {} a customer bought {}.\"\n",
    "    raw_data = raw_data.set_index(\"order_id\")\n",
    "    raw_data_masked = raw_data_masked.set_index(\"order_id\")\n",
    "    for idx in raw_data.index.unique():\n",
    "        items = \", \".join(raw_data.loc[idx][\"target_text\"])\n",
    "        items_masked = \", \".join(raw_data_masked.loc[idx][\"target_text\"])\n",
    "        formated_data.loc[idx, \"target_text\"] = FORMAT.format(idx, items)\n",
    "        formated_data.loc[idx, \"source_text\"] = FORMAT.format(idx, items_masked)\n",
    "\n",
    "    formated_data.to_csv(DATA_SAVE_PATH, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         source_text  \\\n0  On order 1 a customer bought [MASK], Organic 4...   \n1  On order 2 a customer bought Organic Egg White...   \n2  On order 3 a customer bought Total 2% with Str...   \n3  On order 4 a customer bought [MASK], Honey/Lem...   \n4  On order 5 a customer bought Bag of Organic Ba...   \n\n                                         target_text  \n0  On order 1 a customer bought Bulgarian Yogurt(...  \n1  On order 2 a customer bought Organic Egg White...  \n2  On order 3 a customer bought Total 2% with Str...  \n3  On order 4 a customer bought Plain Pre-Sliced ...  \n4  On order 5 a customer bought Bag of Organic Ba...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_text</th>\n      <th>target_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>On order 1 a customer bought [MASK], Organic 4...</td>\n      <td>On order 1 a customer bought Bulgarian Yogurt(...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>On order 2 a customer bought Organic Egg White...</td>\n      <td>On order 2 a customer bought Organic Egg White...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>On order 3 a customer bought Total 2% with Str...</td>\n      <td>On order 3 a customer bought Total 2% with Str...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>On order 4 a customer bought [MASK], Honey/Lem...</td>\n      <td>On order 4 a customer bought Plain Pre-Sliced ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>On order 5 a customer bought Bag of Organic Ba...</td>\n      <td>On order 5 a customer bought Bag of Organic Ba...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = pd.read_csv(DATA_SAVE_PATH)\n",
    "my_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Set model, tokenizer, and data_collator variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Get data and divide into train, eval, and test sets\n",
    "We use 80% of the data for training, 10% for evaluation, and 10% for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             source_text  \\\n22652  On order 23139 a customer bought Organic Avoca...   \n42695  On order 43680 a customer bought First Prunes(...   \n38279  On order 39159 a customer bought [MASK], Koshe...   \n78622  On order 80380 a customer bought Organic Baby ...   \n15252  On order 15570 a customer bought Sharp Cheddar...   \n\n                                             target_text  \n22652  On order 23139 a customer bought Organic Avoca...  \n42695  On order 43680 a customer bought First Prunes(...  \n38279  On order 39159 a customer bought Organic Diced...  \n78622  On order 80380 a customer bought Organic Baby ...  \n15252  On order 15570 a customer bought Sharp Cheddar...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_text</th>\n      <th>target_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22652</th>\n      <td>On order 23139 a customer bought Organic Avoca...</td>\n      <td>On order 23139 a customer bought Organic Avoca...</td>\n    </tr>\n    <tr>\n      <th>42695</th>\n      <td>On order 43680 a customer bought First Prunes(...</td>\n      <td>On order 43680 a customer bought First Prunes(...</td>\n    </tr>\n    <tr>\n      <th>38279</th>\n      <td>On order 39159 a customer bought [MASK], Koshe...</td>\n      <td>On order 39159 a customer bought Organic Diced...</td>\n    </tr>\n    <tr>\n      <th>78622</th>\n      <td>On order 80380 a customer bought Organic Baby ...</td>\n      <td>On order 80380 a customer bought Organic Baby ...</td>\n    </tr>\n    <tr>\n      <th>15252</th>\n      <td>On order 15570 a customer bought Sharp Cheddar...</td>\n      <td>On order 15570 a customer bought Sharp Cheddar...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SPLIT_SEED = 42\n",
    "train_df = my_data.sample(frac = 0.8, random_state=TRAIN_SPLIT_SEED)\n",
    "eval_df = my_data.drop(train_df.index).sample(frac = 0.5, random_state=TRAIN_SPLIT_SEED)\n",
    "test_df = my_data.drop(train_df.index).drop(eval_df.index)\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Create a dataset dict from the dataframes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train': (78266, 3), 'eval': (9784, 3), 'test': (9783, 3)}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"eval\": Dataset.from_pandas(eval_df),\n",
    "    \"test\": Dataset.from_pandas(test_df),\n",
    "    })\n",
    "my_dataset.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Downsample the dataset to 10,000 examples for training, 1,000 for evaluation, and 1,000 for testing for the sake of fast training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['source_text', 'target_text', '__index_level_0__'],\n        num_rows: 10000\n    })\n    test: Dataset({\n        features: ['source_text', 'target_text', '__index_level_0__'],\n        num_rows: 1000\n    })\n    eval: Dataset({\n        features: ['source_text', 'target_text', '__index_level_0__'],\n        num_rows: 1000\n    })\n})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 10000\n",
    "test_size = train_size // 10\n",
    "eval_size = train_size // 10\n",
    "\n",
    "down_sampled_ds = my_dataset[\"train\"].train_test_split(train_size=train_size, test_size=test_size + eval_size, seed=TRAIN_SPLIT_SEED)\n",
    "test_valid = down_sampled_ds[\"test\"].train_test_split(train_size=eval_size, test_size=test_size, seed=TRAIN_SPLIT_SEED)\n",
    "down_sampled_ds[\"eval\"] = test_valid[\"train\"]\n",
    "down_sampled_ds[\"test\"] = test_valid[\"test\"]\n",
    "down_sampled_ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Tokenize the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fbcae2103184e58a4edaac1d5ea5663"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efafd3aa893a4192b773f7175af49258"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc0c8cff595044d19e0d983e2d946b8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 512\n",
    "def tokenize(source_texts, target_texts):\n",
    "    model_inputs = tokenizer(text=source_texts, max_length=MAX_LENGTH, truncation=True)\n",
    "    labels = tokenizer(text_target=target_texts, max_length=MAX_LENGTH, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "tokenized_dataset = down_sampled_ds.map(tokenize, input_columns=[\"source_text\", \"target_text\"], remove_columns=[\"source_text\", \"target_text\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Set training arguments\n",
    "Change \"output_directory\" to your desired output directory. You can also change the batch_size, learning_rate, num_train_epochs and other parameters here. See the documentation for more details: [https://huggingface.co/docs/transformers/v4.21.3/en/main_classes/trainer#transformers.TrainingArguments](https://huggingface.co/docs/transformers/v4.21.3/en/main_classes/trainer#transformers.TrainingArguments)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "ON_CUDA_GPU = False\n",
    "if ON_CUDA_GPU:\n",
    "    training_arguments = Seq2SeqTrainingArguments(\n",
    "        \"output_directory\",\n",
    "        learning_rate=0.0001,\n",
    "        weight_decay=0.01,\n",
    "        fp16=True,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=20,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        report_to=\"all\"\n",
    "    )\n",
    "else:\n",
    "    training_arguments = Seq2SeqTrainingArguments(\n",
    "        \"output_directory\",\n",
    "        learning_rate=0.0001,\n",
    "        weight_decay=0.01,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=20,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        report_to=\"all\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. Create a trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    training_arguments,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Enabling MPS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.2.0.dev20231001'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.0)\n",
    "else:\n",
    "    print(\"MPS is not available\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 10. Save the tokenizer and model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(CHECKPOINT_SAVE_PATH)\n",
    "model.save_pretrained(CHECKPOINT_SAVE_PATH)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
